<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>GhostLink | Defend Your Website</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background: #0f1115;
            color: #ffffff;
            margin: 0;
            padding: 0;
        }
        header {
            background-color: #1f1f1f;
            padding: 2rem;
            text-align: center;
            border-bottom: 3px solid #3b82f6;
        }
        h1 {
            font-size: 2.8rem;
            color: #3b82f6;
            margin: 0;
        }
        .container {
            max-width: 800px;
            margin: 2rem auto;
            padding: 1rem 2rem;
            background-color: #1a1a1a;
            border-radius: 12px;
            box-shadow: 0 0 10px rgba(59, 130, 246, 0.2);
        }
        h2 {
            color: #ffffff;
            margin-top: 1.5rem;
        }
        p {
            line-height: 1.6;
            color: #d1d5db;
        }
        footer {
            text-align: center;
            margin: 3rem 0 1rem;
            font-size: 0.9rem;
            color: #6b7280;
        }
    </style>
</head>
<body>
    <header>
        <h1>GhostLink</h1>
        <p>Protect your website from invisible traffic leaks</p>
    </header>
    <div class="container">
        <h2>The Problem</h2>
        <p>
            More than 45% of all internet traffic today is generated by bots — not real humans. <strong>AI models like GPT</strong> and <strong>scraper bots</strong> regularly crawl websites, harvesting content and data without credit or compensation.
        </p>
        <p>
            For content creators and site owners, this means fewer ad impressions, lower search rankings, and lost revenue. As Wired noted in 2023: <em>“Web publishers are being quietly stripped of their traffic while their content trains AI systems for free.”</em>
        </p>
        <p>
            Some bots obey the rules. But many do not. They ignore robots.txt, spoof user agents, or crawl your site constantly — draining server resources while giving nothing back.
        </p>

        <h2>Our Solution</h2>
        <p>
            <strong>GhostLink</strong> is a lightweight tool you can install on any site in minutes. It detects and logs every visit — whether it's from a human, a browser, or a scraper. Based on known keywords and behavioral patterns, GhostLink:
        </p>
        <ul>
            <li>Identifies bots based on User-Agent headers</li>
            <li>Logs traffic with timestamp, IP, and detection flag</li>
            <li>Automatically blocks known bad actors</li>
            <li>Lets you monitor access via a simple web interface</li>
        </ul>
        <p>
            This helps small websites and large publishers alike protect their content, diagnose traffic loss, and take control over who’s allowed to use their data.
        </p>

        <h2>Built for Simplicity</h2>
        <p>
            GhostLink runs on Flask, requires zero databases, and works out of the box. You can install it, deploy it, and start logging bot activity today.
        </p>
    </div>
    <footer>
        &copy; 2025 GhostLink. All rights reserved.
    </footer>
</body>
</html>